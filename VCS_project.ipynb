{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f30550ac-93b0-4cbe-b4fd-7f2e87df23de",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce596a-7f93-4f88-a010-468ed6a286cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed57332-855e-4e53-b7e3-e1402f0124e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from adan_pytorch import Adan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f67cd5-a115-4763-bb45-16699206a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344576ea-3325-4977-abbb-56151400596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import listDataset\n",
    "from model import CSRNet\n",
    "from model_nostride import CSRNet_ns\n",
    "from utils import save_net, load_net, save_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf8b82-087c-40ab-9d2c-2f07d7c528af",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Check for GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01319dd-d710-40dc-86a4-47f7712b5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Is cusa available: {torch.cuda.is_available()}')\n",
    "print(f'Cuda device name: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb0ff5a-cd1b-41ff-a88c-fd05ab31406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c989fc-ab44-4bbc-89d9-0d131c08028d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9a818-c69a-409e-b57d-d46220bb995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2train = 'ShangaiTech/ShanghaiTech/part_A/train_data/images/'\n",
    "path2test = 'ShangaiTech/ShanghaiTech/part_A/test_data/images/'\n",
    "\n",
    "path2den_train = 'ShangaiTech_newdensity/ShangaiTech_newdensity/A/train_data/'\n",
    "path2den_test = 'ShangaiTech_newdensity/ShangaiTech_newdensity/A/test_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4058f353-7d47-4657-849d-9433a9c252f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(listDataset([path2train + i for i in os.listdir(path2train)],\n",
    "                                                       [path2den_train + i.replace('jpg', 'npy').replace('IMG', 'DEN') for i in os.listdir(path2train)],\n",
    "                                                       shuffle=True,\n",
    "                                                       transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                                     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),]),\n",
    "                                                       train=True,\n",
    "                                                       seen=None,\n",
    "                                                       batch_size=32,\n",
    "                                                       num_workers=4))\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(listDataset([path2test + i for i in os.listdir(path2test)],\n",
    "                                                      [path2den_test + i.replace('jpg', 'npy').replace('IMG', 'DEN') for i in os.listdir(path2test)],\n",
    "                                                      shuffle=True,\n",
    "                                                      transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),]),\n",
    "                                                      train=False,\n",
    "                                                      seen=None,\n",
    "                                                      batch_size=32,\n",
    "                                                      num_workers=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2faddbf-55d3-435f-bb35-2978e2dbe087",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a23f49c-ae11-4093-ac89-a1c10af3892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CSRNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169ef3af-5ac3-443e-80a2-ea9e47cb06d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Criterion and Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc90ff-8fcd-4af5-bf4d-4f5e03da6dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53741380-88f9-4e3a-95ed-4f5df158bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer parameter\n",
    "lr = 1e-7\n",
    "momentum      = 0.95\n",
    "decay         = 5*1e-4\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "                            lr,\n",
    "                            momentum=momentum,\n",
    "                            weight_decay=decay)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "# optimizer = Adan(\n",
    "#     model.parameters(),\n",
    "#     lr = 1e-7,                  # learning rate (can be much higher than Adam, up to 5-10x)\n",
    "#     betas = (0.02, 0.08, 0.01), # beta 1-2-3 as described in paper - author says most sensitive to beta3 tuning\n",
    "#     weight_decay = 0.02         # weight decay 0.02 is optimal per author\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be13fd29-2e55-4434-b9c1-46b543df3356",
   "metadata": {},
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692e59fa-c933-4fd8-8a39-61b3f1f76abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_loader, criterion, optimizer, epoch_index, tb_writer, device):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "  # Here, we use enumerate(training_loader) instead of\n",
    "  # iter(training_loader) so that we can track the batch\n",
    "  # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(train_loader):\n",
    "    #     # Every data instance is an input + label pair\n",
    "        images, density = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(images.to(device))\n",
    "        # print('nan in output: ', outputs.isnan().sum())\n",
    "        # print('nan in density.unsqueeze: ', density.unsqueeze(0).cuda().isnan().sum())\n",
    "\n",
    "        # if i == 0:\n",
    "        #     fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "        #     ax[0].imshow(density.squeeze())\n",
    "        #     ax[1].imshow(outputs.squeeze().cpu().detach().numpy())\n",
    "        #     plt.show()\n",
    "        # Compute the loss and its gradients\n",
    "        loss = criterion(outputs.squeeze(), density.squeeze().to(device))\n",
    "        # print('loss', loss)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            last_loss = running_loss / 10 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07700d-87eb-46ab-83ae-bf9c282596eb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502cff7d-c73d-4657-98b3-720ff8ff3be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "model.train(True)\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train(True)\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    avg_loss = train_one_epoch(train_loader=train_loader, \n",
    "                               criterion = criterion,\n",
    "                               optimizer=optimizer,\n",
    "                               epoch_index=epoch_number,\n",
    "                               tb_writer=writer,\n",
    "                               device=device)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(test_loader):\n",
    "            vinputs, vtarget = vdata\n",
    "            voutputs = model(vinputs.cuda())\n",
    "            vloss = criterion(voutputs, vtarget.unsqueeze(0).cuda())\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'models/model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1801067-ded2-4f6f-8a81-05532144d1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5584e8-8fb1-4ff0-aa51-46470a3dd408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
